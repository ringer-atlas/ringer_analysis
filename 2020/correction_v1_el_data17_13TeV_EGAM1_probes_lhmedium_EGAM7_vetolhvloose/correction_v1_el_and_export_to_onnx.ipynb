{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v1_el tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v2_el r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 22:58:47,795 | Py.crossval_table                       INFO Reading file for v1-el tag from /Volumes/castor/tuning_data/Zee_el/v1/r1/*/*/*.gz\n",
      "2021-04-13 22:58:47,795 | Py.crossval_table                       INFO There are 2500 files for this task...\n",
      "2021-04-13 22:58:47,795 | Py.crossval_table                       INFO Filling the table... \n",
      "2021-04-13 22:59:38,087 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee_el/v1/r1/*/*/*.gz', 'v1-el')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_shower_shapes (InputLayer [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_track_variables (InputLay [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_rings_layer (Dense)       (None, 5)            505         Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_shower_shapes[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_track_variables_layer (De (None, 5)            20          Input_track_variables[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15)           0           dense_rings_layer[0][0]          \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "                                                                 dense_track_variables_layer[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 5)            80          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            6           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 646\n",
      "Trainable params: 646\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = cv.get_best_models(best_sorts, remove_last=False)[0][0]['model']\n",
    "tf.keras.utils.plot_model(model, to_file='model_v1_el_plot.pdf', \n",
    "                          show_shapes=True, \n",
    "                          show_layer_names=True,\n",
    "                          show_dtype=False,\n",
    "                          rankdir='TB',\n",
    "                          expand_nested=True,\n",
    "                          dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "\n",
    "    has_track = d['data'][:,feature_names.index('L2Electron_hastrack')]\n",
    "    d['data'] = d['data'][has_track==True]\n",
    "    target = d['target'][has_track==True]\n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "    avgmu = d['data'][:,0]\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    data_etOverPt  = d['data'][:, feature_names.index('L2Electron_etOverPt')].reshape((n,1))\n",
    "    data_deta      = d['data'][:, feature_names.index('L2Electron_trkClusDeta')].reshape((n,1))\n",
    "    data_dphi      = d['data'][:, feature_names.index('L2Electron_trkClusDphi')].reshape((n,1))\n",
    "    data_track = np.concatenate( (data_etOverPt, data_deta, data_dphi), axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    return [data_rings,data_shower,data_track], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1730.780531s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v1_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226834</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>13176</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>226807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977549</td>\n",
       "      <td>854</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.008054</td>\n",
       "      <td>226852</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.977743</td>\n",
       "      <td>850</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.008017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226995</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>13752</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>226964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>878</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>226987</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.978325</td>\n",
       "      <td>866</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.008168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229203</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>18007</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987815</td>\n",
       "      <td>1338</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>229168</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.987725</td>\n",
       "      <td>1343</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.012666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229358</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>18504</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>229344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>1393</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>229361</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.988557</td>\n",
       "      <td>1391</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.013119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137521</td>\n",
       "      <td>140652</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>26154</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977626</td>\n",
       "      <td>1438</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>137481</td>\n",
       "      <td>140652</td>\n",
       "      <td>0.977455</td>\n",
       "      <td>1450</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.012325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   226834   \n",
       "1  medium_cutbased       0        0                   226995   \n",
       "2   loose_cutbased       0        0                   229203   \n",
       "3  vloose_cutbased       0        0                   229358   \n",
       "4   tight_cutbased       0        1                   137521   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232016              0.977666                        13176   \n",
       "1                  232016              0.978360                        13752   \n",
       "2                  232016              0.987876                        18007   \n",
       "3                  232016              0.988548                        18504   \n",
       "4                  140652              0.977742                        26154   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      106029                  0.124271         226807  ...   \n",
       "1                      106029                  0.129701         226964  ...   \n",
       "2                      106029                  0.169837         229189  ...   \n",
       "3                      106029                  0.174527         229344  ...   \n",
       "4                      117644                  0.222321         137505  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977549                854            106029        0.008054   \n",
       "1    0.978226                878            106029        0.008281   \n",
       "2    0.987815               1338            106029        0.012619   \n",
       "3    0.988484               1393            106029        0.013138   \n",
       "4    0.977626               1438            117644        0.012223   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   226852                  232016              0.977743   \n",
       "1                   226987                  232016              0.978325   \n",
       "2                   229168                  232016              0.987725   \n",
       "3                   229361                  232016              0.988557   \n",
       "4                   137481                  140652              0.977455   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                          850                      106029   \n",
       "1                          866                      106029   \n",
       "2                         1343                      106029   \n",
       "3                         1391                      106029   \n",
       "4                         1450                      117644   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.008017  \n",
       "1                  0.008168  \n",
       "2                  0.012666  \n",
       "3                  0.013119  \n",
       "4                  0.012325  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 19:13:49,110 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v1_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v1 el tuning', \n",
    "                                              'correction_v1_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronTight.et4_eta4.onnx\n",
      "2021-03-06 19:15:14,309 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronMedium.et4_eta4.onnx\n",
      "2021-03-06 19:16:17,281 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronLoose.et4_eta4.onnx\n",
      "2021-03-06 19:17:20,013 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electronVeryLoose.et4_eta4.onnx\n",
      "2021-03-06 19:18:22,137 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 19:14:10.733768: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:10.758249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec0bd0eaf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:10.758271: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:14.375353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:14.395675: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd300b97200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:14.395707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:17.545145: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:17.560550: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f87897c3a30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:17.560626: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:20.525245: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:20.538121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6a1d79120 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:20.538137: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:23.061867: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:23.083604: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc7f5387fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:23.083620: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:25.595864: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:25.608679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdbadd692d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:25.608694: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:28.115938: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:28.130531: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc26597410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:28.130547: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:30.659089: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:30.672588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95c941aa60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:30.672619: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:33.158088: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:33.172045: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f984fb4ec50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:33.172069: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:35.765821: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:35.779390: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda4c05fc30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:35.779406: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:38.262503: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:38.276125: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f977c2edcb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:38.276147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:40.848241: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:40.861164: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe18141d140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:40.861188: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:43.357242: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:43.371823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdc3f46de60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:43.371840: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:45.859864: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:45.875483: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85c369a710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:45.875507: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:48.376696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:48.389279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfd7433ba0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:48.389294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:50.953337: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:50.967155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2cbc229e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:50.967169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:53.436786: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:53.449584: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4fbcfab00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:53.449599: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:55.936271: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:55.949270: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff9f0d324f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:55.949285: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:14:58.454366: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:14:58.467806: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbee45f2d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:14:58.467820: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:01.033395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:01.046536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd9ddde4c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:01.046551: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:03.540751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:03.553851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c584dded0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:03.553866: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:06.044305: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:06.057484: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6744241a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:06.057500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:08.550482: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:08.563551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc991d41970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:08.563568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:11.104806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:11.118009: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9319b98270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:11.118024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:13.587171: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:13.600314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd30857f4a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:13.600330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:16.450239: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:16.462990: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd7ec4a78e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:16.463005: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:18.943715: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:18.956698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5a1514640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:18.956713: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:21.486280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:21.499409: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fde67d8e510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:21.499425: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:23.949935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:23.962917: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7eea54ae80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:23.962933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:26.441234: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:26.454089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd37d9f9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:26.454104: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:28.911522: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:28.924292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcfbaf0300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:28.924306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:31.426480: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:31.439385: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb7d3a13d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:31.439401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:33.875118: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:33.888201: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc706aa810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:33.888216: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:36.370961: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:36.383688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffcc34612a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:36.383703: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:38.845408: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:38.859873: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe7deb89580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:38.859889: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:41.380828: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:41.393763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff9aee09db0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:41.393778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:43.882969: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:43.895819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff28a631ec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:43.895834: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:46.370970: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:46.384516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd939d56060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:46.384531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:48.860974: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:48.874055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9f8c78a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:48.874076: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:51.386028: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:51.398835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2654ef490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:51.398853: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:53.910350: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:53.924772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff65d570fa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:53.924793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:56.508535: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:56.521591: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd7edd44300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:56.521606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:15:59.084558: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:15:59.098166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee19573910 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:15:59.098181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:01.724197: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:01.737635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe85ed3c820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:01.737651: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:04.307724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:04.321581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8fbfb3ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:04.321598: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:06.800201: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:06.813405: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdec153cb00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:06.813421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:09.333810: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:09.347057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fceb8bbdeb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:09.347073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:11.846831: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:11.859299: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f94c6bba2a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:11.859318: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:14.329765: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:14.343070: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6b0c00480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:14.343087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:16.913266: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:16.943417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe202e4cbe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:16.943434: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:19.455277: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:19.469127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b50cdd380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:19.469143: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:21.973271: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:21.986332: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc39efc9460 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:21.986348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:24.457414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:24.478966: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc389ba5c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:24.478990: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:27.002595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:27.015752: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fad25d7b8b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:27.015767: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:29.532067: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:29.545580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0f2517620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:29.545595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:32.079669: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:32.092455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb68b077a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:32.092475: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:34.603550: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:34.616751: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbca9d1e650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:34.616766: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:37.102050: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:37.115173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92a9fd52d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:37.115188: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:39.614443: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:39.627162: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb97c268ad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:39.627177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:42.094962: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:42.108143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd22abd2b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:42.108163: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:44.563617: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:44.577277: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcfcbd57b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:44.577293: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:47.037847: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:47.051052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f15e19490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:47.051068: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:49.505572: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:49.518960: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc64aea6e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:49.518977: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:51.996600: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:52.009474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8434d5ad70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:52.009489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:54.449498: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:54.462625: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faea2675780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:54.462642: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:56.949399: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:56.962207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2fa615540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:56.962222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:16:59.449354: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:16:59.463009: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd2e6bf4ae0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:16:59.463024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:01.972843: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:01.987035: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb304989610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:01.987050: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:04.439532: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:04.453086: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa842c697a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:04.453101: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:06.927489: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:06.942249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f84598b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:06.942264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:09.577727: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:09.591514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfd3d0cd10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:09.591528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:12.190121: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:12.204406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8801370a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:12.204422: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:14.678765: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:14.692453: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd8ee17220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:14.692469: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:17.142952: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:17.155562: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa78d4155b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:17.155577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:19.665569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:19.678920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa19437e3e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:19.678938: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:22.165152: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:22.178346: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc5dad419b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:22.178361: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:24.642676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:24.656132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0b5daf4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:24.656147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:27.118209: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:27.131237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96f75c5a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:27.131252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:29.620853: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:29.634715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0a1617970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:29.634731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:32.074789: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:32.087719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec0ad825a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:32.087734: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:34.561445: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:34.574105: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb87343cfd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:34.574119: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:37.008797: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:37.021470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99688bd0e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:37.021485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:39.494117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:39.507919: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7febe05e6550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:39.507935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:41.967877: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:41.980831: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e55981090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:41.980848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:44.474411: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:44.487290: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa89cc37f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:44.487306: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:46.960114: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:46.973224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb17a4b3d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:46.973239: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:49.455591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:49.468608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9c8c59830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:49.468623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:51.918595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:51.931456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f882652c870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:51.931470: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:54.410805: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:54.423559: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f843f617600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:54.423574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:56.896654: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:56.909736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f842dc5fa20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:56.909751: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:17:59.376382: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:17:59.390547: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f867cd486a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:17:59.390563: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:01.862554: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:01.875076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc18f360110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:01.875091: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:04.383154: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:04.396018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fad844e6cb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:04.396034: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:06.859054: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:06.871957: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff1ed57b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:06.871971: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:09.374330: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:09.387753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9301558010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:09.387769: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:11.845267: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:11.858216: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcdae77b4d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:11.858231: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:14.363892: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:14.376725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9826677500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:14.376740: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:16.817456: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:16.830266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0715ba7e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:16.830282: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:19.315036: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:19.328404: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee945e0a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:19.328420: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 19:18:21.783064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 19:18:21.795705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd4759ac80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 19:18:21.795720: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 24 -> 15\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v1_el.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
