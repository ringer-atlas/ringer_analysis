{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v10 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v10 r2 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-13 22:45:36,472 | Py.crossval_table                       INFO Reading file for v10 tag from /Volumes/castor/tuning_data/Zee/v10/r2/*/*/*.gz\n",
      "2021-04-13 22:45:36,473 | Py.crossval_table                       INFO There are 2500 files for this task...\n",
      "2021-04-13 22:45:36,473 | Py.crossval_table                       INFO Filling the table... \n",
      "2021-04-13 22:46:48,065 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v10/r2/*/*/*.gz', 'v10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "Reshape_layer (Reshape)      (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_layer_1 (Conv1D)      (None, 99, 4)             12        \n",
      "_________________________________________________________________\n",
      "conv1d_layer_2 (Conv1D)      (None, 98, 8)             72        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "output_for_inference (Dense) (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 12,661\n",
      "Trainable params: 12,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = cv.get_best_models(best_sorts, remove_last=False)[0][0]['model']\n",
    "tf.keras.utils.plot_model(model, to_file='model_v10_plot.pdf', \n",
    "                          show_shapes=True, \n",
    "                          show_layer_names=True,\n",
    "                          show_dtype=False,\n",
    "                          rankdir='TB',\n",
    "                          dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1925.086415s.\n",
      "2021-03-06 13:48:01,182 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 13:48:19,588 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 13:48:56,696 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 13:49:11,534 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 13:49:16,371 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 13:49:21,232 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 13:49:25,671 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v10_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977467</td>\n",
       "      <td>3467</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>227566</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977437</td>\n",
       "      <td>3380</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978245</td>\n",
       "      <td>3534</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>227725</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>3442</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987797</td>\n",
       "      <td>4974</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>229960</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987720</td>\n",
       "      <td>4783</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.025490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988459</td>\n",
       "      <td>5128</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>230139</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988489</td>\n",
       "      <td>4948</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.026370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977574</td>\n",
       "      <td>4505</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.031359</td>\n",
       "      <td>137841</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977596</td>\n",
       "      <td>4379</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.030482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227573  ...   \n",
       "1                      187639                  0.129701         227754  ...   \n",
       "2                      187639                  0.169837         229978  ...   \n",
       "3                      187639                  0.174527         230132  ...   \n",
       "4                      143657                  0.222321         137838  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977467               3467            187639        0.018477   \n",
       "1    0.978245               3534            187639        0.018834   \n",
       "2    0.987797               4974            187639        0.026508   \n",
       "3    0.988459               5128            187639        0.027329   \n",
       "4    0.977574               4505            143657        0.031359   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227566                  232819              0.977437   \n",
       "1                   227725                  232819              0.978120   \n",
       "2                   229960                  232819              0.987720   \n",
       "3                   230139                  232819              0.988489   \n",
       "4                   137841                  141000              0.977596   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         3380                      187639   \n",
       "1                         3442                      187639   \n",
       "2                         4783                      187639   \n",
       "3                         4948                      187639   \n",
       "4                         4379                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.018013  \n",
       "1                  0.018344  \n",
       "2                  0.025490  \n",
       "3                  0.026370  \n",
       "4                  0.030482  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 13:49:27,829 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v10_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v10 tuning', \n",
    "                                              'correction_v10_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronTight.et4_eta4.onnx\n",
      "2021-03-06 13:50:59,754 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronMedium.et4_eta4.onnx\n",
      "2021-03-06 13:52:06,449 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronLoose.et4_eta4.onnx\n",
      "2021-03-06 13:53:21,938 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electronVeryLoose.et4_eta4.onnx\n",
      "2021-03-06 13:54:31,843 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 13:49:50.055405: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:49:50.092947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9dd4c56530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:49:50.092963: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:49:53.104717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:49:53.118421: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe5c584b4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:49:53.118437: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:49:56.112038: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:49:56.126895: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd775a5a7e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:49:56.126913: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:49:59.424203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:49:59.437934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f921955b6b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:49:59.437950: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:02.442610: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:02.459247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f918c0af0b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:02.459272: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:05.242720: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:05.261069: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc21389df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:05.261106: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:08.001155: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:08.015700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ce66641f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:08.015716: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:10.722369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:10.735632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fafee4755b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:10.735648: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:13.591086: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:13.605413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7fdc4aead0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:13.605429: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:16.184002: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:16.197470: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4e7d580f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:16.197499: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:19.196617: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:19.210607: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fab34ca81b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:19.210627: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:21.982743: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:22.004642: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85d23ce360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:22.004668: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:24.787580: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:24.801442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9535ce0440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:24.801456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:27.924675: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:27.939211: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc16b4f3a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:27.939227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:30.832425: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:30.845757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd62ad734b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:30.845772: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:34.341685: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:34.356085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc6cd513b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:34.356109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:37.137044: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:37.151081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd08048c220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:37.151109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:39.812628: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:39.825679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7febd7577540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:39.825695: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:42.431403: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:42.444372: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faee18d6150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:42.444388: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:45.235763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:45.249916: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffaf54d5e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:45.249937: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:47.954211: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:47.967887: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa204c33a80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:47.967902: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:50.535988: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:50.549787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc2b639fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:50.549808: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:53.236090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:53.249159: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8006d0a180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:53.249174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:56.051419: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:56.064696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f74435bf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:56.064713: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:50:58.983263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:50:58.996947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc32dcc6dd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:50:58.996962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:02.103830: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:02.116518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb21b76bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:02.116534: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:04.685808: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:04.698829: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb8abd78670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:04.698845: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:07.616035: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:07.632691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8c41f3ba0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:07.632714: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:10.319900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:10.333653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8dc0646280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:10.333669: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:12.877924: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:12.891012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcbc2da1210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:12.891027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:15.580754: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:15.593717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a38499c50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:15.593732: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:18.165058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:18.178885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe6ebc0c7e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:18.178900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:20.793208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:20.807100: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9369551840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:20.807116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:23.494428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:23.509663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d751bdfa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:23.509747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:26.237296: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:26.250672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3afca6bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:26.250690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:28.820381: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:28.834446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff7953752e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:28.834464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:31.363275: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:31.376499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe77ad02250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:31.376515: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:33.955053: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:33.975194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9ad5d59d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:33.975248: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:36.710741: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:36.724034: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbeb7c02d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:36.724054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:39.369199: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:39.382042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe113e1ed0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:39.382058: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:41.901855: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:41.915210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc64600880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:41.915225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:44.541099: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:44.554601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdfb9694250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:44.554615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:47.089334: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:47.101939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba14c34360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:47.101954: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:49.731372: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:49.751153: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d1745a8e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:49.751170: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:52.602697: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:52.616017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4f19c2af0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:52.616032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:55.315949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:55.328896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f783f19b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:55.328912: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:51:57.887213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:51:57.902304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5dfda4ac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:51:57.902324: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:00.756799: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:00.770329: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb464628c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:00.770345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:03.542980: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:03.558901: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdea9552aa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:03.558917: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:06.090745: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:06.104336: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9015df260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:06.104352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:08.841416: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:08.855380: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f815abf4520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:08.855397: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:11.510276: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:11.523809: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f37c6ce80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:11.523829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:14.438645: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:14.451804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb031f1b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:14.451820: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:17.168066: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:17.181448: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90a2c25010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:17.181462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:21.094704: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:21.116195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0bfbdb5b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:21.116211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:24.280842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:24.293428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe599f66e70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:24.293443: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:27.181204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:27.215734: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0ab48a020 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:27.215805: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:32.107510: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:32.134268: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd79c51d4f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:32.134354: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:35.926083: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:35.949178: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc060620880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:35.949229: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:39.208898: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:39.222393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe805e4fc10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:39.222409: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:41.892294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:41.905038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85ed734c10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:41.905053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:44.545179: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:44.558861: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffdcdcf3490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:44.558877: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:47.195012: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:47.208089: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa136d90180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:47.208104: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:49.797335: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:49.810637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa97fe2aba0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:49.810653: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:53.567758: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:53.585654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fab76c5f830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:53.585797: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:56.737133: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:56.750415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa805640aa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:56.750435: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:52:59.681495: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:52:59.696028: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea26d22860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:52:59.696045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:02.280207: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:02.293063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf91ed4a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:02.293078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:04.826410: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:04.839414: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f802e73ef50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:04.839429: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:07.373557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:07.386412: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe44fd13dc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:07.386428: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:10.171728: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:10.191944: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6f054f6d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:10.191977: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:13.055350: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:13.068027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdec9c490e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:13.068042: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:15.822453: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:15.835465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f919d562160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:15.835481: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:18.451048: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:18.465088: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc915746d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:18.465103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:21.445028: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:21.458862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf5bbccf10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:21.458878: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:24.344764: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:24.357738: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb581da7210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:24.357753: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:27.222071: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:27.234977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbeab392560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:27.234993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:31.092125: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:31.106947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7fb8761b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:31.106964: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:33.722789: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:33.736238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7febb4c33f10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:33.736260: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:36.266446: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:36.279466: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa39dc53a60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:36.279482: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:38.855405: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:38.868900: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3aa570490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:38.868916: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:41.416957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:41.429778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa373ce92f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:41.429793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:44.362208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:44.375204: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b2c7611d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:44.375225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:47.213182: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:47.226296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6d49ba8e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:47.226311: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:49.871363: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:49.884557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8cafd31460 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:49.884572: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:52.434284: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:52.447368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c602f17f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:52.447384: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:54.979189: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:54.991930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa29873b520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:54.991946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:53:57.741972: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:53:57.755179: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc57556c190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:53:57.755195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:00.454285: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:00.467392: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb66d5a8c90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:00.467407: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:03.346409: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:03.360624: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8dfa84c820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:03.360640: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:05.979575: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:05.992927: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac0bfa23a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:05.992942: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:08.555659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:08.569330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda042a4530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:08.569345: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:11.499786: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:11.518027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd4169d11c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:11.518043: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:14.177719: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:14.190939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb5ab505660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:14.190956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:17.048706: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:17.062105: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feb03c58000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:17.062120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:20.146881: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:20.171472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ae8d6e9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:20.171489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:22.795783: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:22.808928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa37b433c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:22.808944: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:25.766741: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:25.780077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9bb3e09690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:25.780094: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:28.910712: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:28.923819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe52f42bf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:28.923834: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:54:31.480955: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:54:31.493976: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb069faffb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:54:31.493992: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 20 -> 12\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v10.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
