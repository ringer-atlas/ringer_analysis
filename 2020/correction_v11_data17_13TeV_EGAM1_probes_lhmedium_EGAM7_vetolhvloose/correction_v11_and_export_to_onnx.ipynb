{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v11 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v11 r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 19:29:11,307 | Py.crossval_table                       INFO Reading file for v11 tag from /Volumes/castor/tuning_data/Zee/v11/*.v11_et*.r3/*/*.gz\n",
      "2020-12-27 19:29:11,307 | Py.crossval_table                       INFO There are 1250 files for this task...\n",
      "2020-12-27 19:29:11,307 | Py.crossval_table                       INFO Filling the table... \n",
      "2020-12-27 19:29:50,516 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v11/*.v11_et*.r3/*/*.gz', 'v11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 1)       0           Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_1 (Conv1D)         (None, 98, 4)        16          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_2 (Conv1D)         (None, 96, 8)        104         conv1d_rings_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Input_shower_shapes (InputLayer [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 768)          0           conv1d_rings_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_shower_shapes[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 773)          0           flatten[0][0]                    \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 16)           12384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            17          dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,556\n",
      "Trainable params: 12,556\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings,data_shower], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1875.165602s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v11_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977515</td>\n",
       "      <td>2630</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.014016</td>\n",
       "      <td>227562</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977420</td>\n",
       "      <td>2582</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.013760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978159</td>\n",
       "      <td>2683</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>227701</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978017</td>\n",
       "      <td>2624</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.013984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987780</td>\n",
       "      <td>3682</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>230013</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987948</td>\n",
       "      <td>3601</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.019191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988442</td>\n",
       "      <td>3774</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.020113</td>\n",
       "      <td>230146</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988519</td>\n",
       "      <td>3699</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.019713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977532</td>\n",
       "      <td>3504</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>137807</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977355</td>\n",
       "      <td>3399</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.023661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227584  ...   \n",
       "1                      187639                  0.129701         227734  ...   \n",
       "2                      187639                  0.169837         229974  ...   \n",
       "3                      187639                  0.174527         230128  ...   \n",
       "4                      143657                  0.222321         137832  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977515               2630            187639        0.014016   \n",
       "1    0.978159               2683            187639        0.014299   \n",
       "2    0.987780               3682            187639        0.019623   \n",
       "3    0.988442               3774            187639        0.020113   \n",
       "4    0.977532               3504            143657        0.024391   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227562                  232819              0.977420   \n",
       "1                   227701                  232819              0.978017   \n",
       "2                   230013                  232819              0.987948   \n",
       "3                   230146                  232819              0.988519   \n",
       "4                   137807                  141000              0.977355   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         2582                      187639   \n",
       "1                         2624                      187639   \n",
       "2                         3601                      187639   \n",
       "3                         3699                      187639   \n",
       "4                         3399                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.013760  \n",
       "1                  0.013984  \n",
       "2                  0.019191  \n",
       "3                  0.019713  \n",
       "4                  0.023661  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 20:01:10,973 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v11_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v11 tuning', \n",
    "                                              'correction_v11_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta4.onnx\n",
      "2020-12-27 20:02:26,970 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta4.onnx\n",
      "2020-12-27 20:03:25,415 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta4.onnx\n",
      "2020-12-27 20:04:23,881 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta4.onnx\n",
      "2020-12-27 20:05:22,215 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-27 20:01:29.996603: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:30.023708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca5c0e7ed0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:30.023729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:32.362632: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:32.375452: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc47b393060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:32.375468: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:34.741644: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:34.754493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9e6cf51c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:34.754508: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:37.113630: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:37.126967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fadd54730b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:37.126988: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:39.503016: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:39.515455: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea71ff9b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:39.515471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:41.856538: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:41.868970: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d7d8c7b50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:41.868985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:44.225991: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:44.240935: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8c3cb1c10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:44.240950: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:46.565421: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:46.578703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8546e0d810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:46.578731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:48.914768: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:48.928075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f805de130a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:48.928102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:51.260375: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:51.272782: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9cb1cf1680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:51.272796: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:53.593285: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:53.605599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9394cc7da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:53.605614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:55.935957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:55.950205: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4c3543340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:55.950222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:01:58.295013: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:01:58.307967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe453816630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:01:58.307985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:00.655008: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:00.667837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc1e7cd4cd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:00.667854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:03.006854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:03.019199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcdbd77fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:03.019213: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:05.385917: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:05.400115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b0ed8a630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:05.400132: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:07.750438: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:07.763462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc1a9d429c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:07.763478: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:10.113478: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:10.126057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f851f5641f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:10.126071: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:12.495557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:12.508280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea7fbea500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:12.508296: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:14.821796: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:14.834030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea895945b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:14.834044: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:17.165363: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:17.177961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9af71e4640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:17.177976: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:19.509703: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:19.522153: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe1a6f83e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:19.522167: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:21.854237: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:21.866723: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1d1885990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:21.866738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:24.205179: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:24.218110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd97088310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:24.218125: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:26.530485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:26.542948: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe22bf8640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:26.542962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:28.942158: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:28.955113: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc36ad03c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:28.955128: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:31.280177: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:31.294602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6244076c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:31.294638: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:33.611454: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:33.624251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd01b5bcb10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:33.624265: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:35.963540: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:35.975983: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff92de61170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:35.975999: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:38.306549: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:38.319208: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4efc8cb40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:38.319223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:40.651391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:40.663937: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa05ecb01c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:40.663953: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:42.965899: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:42.978884: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa341e1e6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:42.978899: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:45.281138: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:45.293698: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe63fc0e6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:45.293713: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:47.621514: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:47.633840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99170aab90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:47.633857: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:49.929521: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:49.942033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8822de6900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:49.942048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:52.282780: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:52.295545: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe98cf4c570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:52.295560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:54.625509: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:54.638398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd711dea7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:54.638413: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:56.940430: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:56.953064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff86e3b18d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:56.953078: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:02:59.297463: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:02:59.310232: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd4374808c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:02:59.310247: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:01.630379: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:01.643058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91217c5e90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:01.643074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:03.966541: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:03.979523: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fefff4f43b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:03.979538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:06.321000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:06.333450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea5c6549d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:06.333465: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:08.651569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:08.664396: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0fcc7b700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:08.664413: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:10.994495: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:11.007609: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcbc4bf3a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:11.007624: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:13.305754: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:13.318246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb4f87f5370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:13.318261: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:15.647607: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:15.660010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf00089890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:15.660025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:17.993964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:18.006441: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff47844b420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:18.006457: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:20.343346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:20.355974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0767358d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:20.355988: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:22.678260: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:22.691269: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffe1103d2e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:22.691285: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:25.021437: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:25.034403: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe25e54d5a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:25.034421: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:27.375652: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:27.388082: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3635a1900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:27.388097: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:29.730533: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:29.742668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6343e2250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:29.742682: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:32.149835: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:32.162210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb60d017a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:32.162226: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:34.486461: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:34.498967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca8d5dc880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:34.498985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:36.801071: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:36.813686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee7563fa40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:36.813701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:39.156148: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:39.168832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd7a66c9cd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:39.168847: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:41.501610: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:41.514948: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f665b5bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:41.514963: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:43.853369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:43.865468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa36fe24190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:43.865484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:46.182484: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:46.195031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9700431c20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:46.195047: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:48.535042: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:48.547737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe568d86a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:48.547753: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:50.854418: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:50.866807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99ea57dc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:50.866825: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:53.178451: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:53.190875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba7473d7b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:53.190892: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:55.494175: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:55.506613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb5843dae50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:55.506628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:03:57.820534: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:03:57.833404: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e1ae3ba50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:03:57.833418: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:00.175518: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:00.188366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe12d582740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:00.188382: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:02.536464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:02.549527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa62bb0f750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:02.549542: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:04.882827: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:04.895448: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcf9e5881a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:04.895464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:07.212416: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:07.224801: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f939df843a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:07.224815: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:09.566779: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:09.579441: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff39434af80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:09.579456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:11.894512: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:11.906972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85f3d733b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:11.906986: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:14.217738: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:14.230388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7facb45eab60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:14.230403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:16.535918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:16.548599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff9aeda4bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:16.548615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:18.865395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:18.878962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff227d81470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:18.878977: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:21.182098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:21.194685: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe017629dd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:21.194701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:23.491353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:23.504064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90c654edf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:23.504079: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:25.813551: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:25.826003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fecdfc9ead0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:25.826018: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:28.135077: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:28.147653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb6a392ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:28.147668: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:30.455303: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:30.467600: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffab5cc1280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:30.467615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:32.783311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:32.795805: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2b6d30580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:32.795821: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:35.127506: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:35.139786: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f88c144dab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:35.139801: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:37.459721: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:37.472369: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd779a6e6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:37.472383: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:39.782142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:39.794672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9bc6f4860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:39.794687: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:42.112449: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:42.124835: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f962ad2ce80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:42.124850: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:44.426569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:44.438827: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa130cafe50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:44.438841: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:46.759230: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:46.771863: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f994fe4cd60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:46.771877: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:49.090770: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:49.103335: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb188d4eb30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:49.103350: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:51.417267: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:51.429594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8fe5d5cc90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:51.429609: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:53.743755: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:53.756239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe19357d250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:53.756255: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:56.062294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:56.074784: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e7bd58fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:56.074799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:04:58.409601: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:04:58.422108: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4add474c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:04:58.422124: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:00.759549: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:00.772462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f93a99130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:00.772477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:03.075450: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:03.088331: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0125d98c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:03.088347: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:05.459412: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:05.471961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f81a4d495f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:05.471975: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:07.781582: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:07.794632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca2cd86d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:07.794647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:10.115608: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:10.128202: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95b75e9e60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:10.128216: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:12.473751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:12.486364: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f821b58f9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:12.486379: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:14.800900: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:14.813205: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2d9c84c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:14.813219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:17.148500: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:17.161487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f911358c150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:17.161501: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:19.497051: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:19.509480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3acd240b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:19.509495: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 20:05:21.818377: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 20:05:21.831267: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe348d3c210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 20:05:21.831282: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
