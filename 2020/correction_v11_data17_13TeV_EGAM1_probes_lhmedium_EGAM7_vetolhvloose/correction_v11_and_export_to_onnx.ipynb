{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v11 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v11 r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 14:33:40,576 | Py.crossval_table                       INFO Reading file for v11 tag from /Volumes/castor/tuning_data/Zee/v11/r1/*/*/*.gz\n",
      "2021-03-06 14:33:40,576 | Py.crossval_table                       INFO There are 2500 files for this task...\n",
      "2021-03-06 14:33:40,576 | Py.crossval_table                       INFO Filling the table... \n",
      "2021-03-06 14:34:52,707 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v11/r1/*/*/*.gz', 'v11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 1)       0           Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_1 (Conv1D)         (None, 99, 4)        12          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_2 (Conv1D)         (None, 98, 8)        72          conv1d_rings_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Input_shower_shapes (InputLayer [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           conv1d_rings_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_shower_shapes[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 789)          0           flatten[0][0]                    \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 16)           12640       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            17          dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,776\n",
      "Trainable params: 12,776\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings,data_shower], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1973.180397s.\n",
      "2021-03-06 15:06:34,930 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:06:50,765 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:07:06,319 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:07:22,117 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:07:35,924 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:07:40,192 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:07:44,406 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 15:07:48,646 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v11_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977480</td>\n",
       "      <td>2564</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.013665</td>\n",
       "      <td>227589</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977536</td>\n",
       "      <td>2491</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.013275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978232</td>\n",
       "      <td>2606</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>227757</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978258</td>\n",
       "      <td>2522</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.013441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987806</td>\n",
       "      <td>3537</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>229982</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987815</td>\n",
       "      <td>3464</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.018461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988459</td>\n",
       "      <td>3628</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>230150</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988536</td>\n",
       "      <td>3571</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.019031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977610</td>\n",
       "      <td>3307</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.023020</td>\n",
       "      <td>137824</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977475</td>\n",
       "      <td>3243</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.022575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227576  ...   \n",
       "1                      187639                  0.129701         227751  ...   \n",
       "2                      187639                  0.169837         229980  ...   \n",
       "3                      187639                  0.174527         230132  ...   \n",
       "4                      143657                  0.222321         137843  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977480               2564            187639        0.013665   \n",
       "1    0.978232               2606            187639        0.013888   \n",
       "2    0.987806               3537            187639        0.018850   \n",
       "3    0.988459               3628            187639        0.019335   \n",
       "4    0.977610               3307            143657        0.023020   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227589                  232819              0.977536   \n",
       "1                   227757                  232819              0.978258   \n",
       "2                   229982                  232819              0.987815   \n",
       "3                   230150                  232819              0.988536   \n",
       "4                   137824                  141000              0.977475   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         2491                      187639   \n",
       "1                         2522                      187639   \n",
       "2                         3464                      187639   \n",
       "3                         3571                      187639   \n",
       "4                         3243                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.013275  \n",
       "1                  0.013441  \n",
       "2                  0.018461  \n",
       "3                  0.019031  \n",
       "4                  0.022575  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 15:07:50,911 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v11_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v11 tuning', \n",
    "                                              'correction_v11_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronTight.et4_eta4.onnx\n",
      "2021-03-06 15:09:15,438 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronMedium.et4_eta4.onnx\n",
      "2021-03-06 15:10:20,246 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronLoose.et4_eta4.onnx\n",
      "2021-03-06 15:11:24,967 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electronVeryLoose.et4_eta4.onnx\n",
      "2021-03-06 15:12:29,729 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 15:08:11.662309: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:11.679659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99015c3770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:11.679677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:14.235598: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:14.248715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee1f689540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:14.248730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:16.840095: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:16.853822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffaa7589b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:16.853837: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:19.481000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:19.495137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc545f5ed60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:19.495154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:22.078238: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:22.093080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8f3cb95b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:22.093097: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:24.673301: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:24.687614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82b29b25f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:24.687633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:27.285397: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:27.298614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f915e6141a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:27.298629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:29.916093: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:29.929648: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe9c48c5b00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:29.929671: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:32.472213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:32.486041: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc83558ddf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:32.486072: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:35.027065: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:35.040575: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c3ad78d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:35.040591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:37.593923: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:37.607001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdeb7e021d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:37.607016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:40.198690: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:40.211421: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb02de2b280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:40.211437: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:42.787832: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:42.800939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff66ebf6150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:42.800955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:45.424214: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:45.439081: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d67d318c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:45.439098: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:48.100226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:48.113637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe837aa4250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:48.113655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:50.787178: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:50.800339: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fed85c475d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:50.800360: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:53.503211: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:53.516010: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f915bcdc630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:53.516025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:56.267211: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:56.283309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6e64cc540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:56.283330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:08:59.023539: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:08:59.040021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a904d98c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:08:59.040040: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:01.632809: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:01.646337: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcac37a0880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:01.646353: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:04.219203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:04.233125: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4a2d0f840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:04.233139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:06.797858: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:06.810549: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa29ad01ec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:06.810565: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:09.439618: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:09.452753: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b3b18c6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:09.452773: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:12.019575: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:12.033473: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff173486c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:12.033489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:14.627031: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:14.642066: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fafdb8a2d30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:14.642084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:17.694246: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:17.707450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd86e38b3e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:17.707466: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:20.461639: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:20.475448: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe0b37b340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:20.475466: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:22.992608: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:23.006173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fccfa5a6910 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:23.006188: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:25.655897: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:25.669347: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca8bcd2160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:25.669362: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:28.226995: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:28.240363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda01e41920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:28.240380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:30.830890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:30.844393: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b32ee8b90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:30.844408: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:33.409217: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:33.422678: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8b12da4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:33.422694: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:35.997813: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:36.011122: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb3840f8f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:36.011154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:38.608346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:38.621493: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb496c941e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:38.621508: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:41.181885: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:41.195212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2e3571930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:41.195227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:43.726745: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:43.739962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd5c4c9dd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:43.739978: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:46.303016: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:46.316080: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9feac05290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:46.316096: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:48.888922: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:48.902978: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc83e492df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:48.902994: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:51.443460: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:51.457042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa80dd356f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:51.457057: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:54.010167: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:54.023287: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d5bec9970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:54.023301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:56.607326: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:56.620614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa522605ff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:56.620634: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:09:59.201722: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:09:59.214789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f81e3c951a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:09:59.214805: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:01.797877: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:01.811058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff357e207b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:01.811074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:04.388014: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:04.401280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea5b16a310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:04.401295: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:06.952694: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:06.965458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb09bcbde0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:06.965474: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:09.574595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:09.587621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb612b8bf10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:09.587637: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:12.129552: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:12.142423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb03df39c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:12.142438: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:14.704867: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:14.717622: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbbe5185860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:14.717639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:17.270663: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:17.283614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd726547550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:17.283630: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:19.877447: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:19.890655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbce42f2cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:19.890671: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:22.451287: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:22.464728: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f904856c870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:22.464743: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:25.009557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:25.022591: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f998b555f20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:25.022606: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:27.604626: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:27.617910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e927bebe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:27.617926: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:30.228422: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:30.241462: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b76b495b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:30.241477: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:32.786278: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:32.799400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85e862e9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:32.799415: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:35.346779: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:35.359678: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f93718019b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:35.359693: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:37.921165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:37.935463: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe858c9b0c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:37.935482: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:40.513075: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:40.526977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe51617080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:40.526997: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:43.087488: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:43.100533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd465e4d650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:43.100549: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:45.655058: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:45.668230: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0b3d07320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:45.668244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:48.203676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:48.217441: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc839cc8f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:48.217457: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:50.824056: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:50.836703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95b64ec1e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:50.836735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:53.395066: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:53.409365: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa93a839630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:53.409381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:55.979174: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:55.992513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc3e5e11850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:55.992529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:10:58.551324: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:10:58.564919: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff600572060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:10:58.564933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:01.137021: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:01.150279: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffbed610d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:01.150294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:03.739253: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:03.752477: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80fee4bc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:03.752492: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:06.320395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:06.333101: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9dd7d07a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:06.333117: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:08.947072: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:08.960944: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb781c61090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:08.960960: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:11.502696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:11.515836: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9036e04ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:11.515852: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:14.130564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:14.143875: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f85a8d25290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:14.143891: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:16.832848: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:16.845576: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc1264186f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:16.845592: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:19.427493: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:19.440635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe00045dc70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:19.440650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:22.008944: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:22.022246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa8b9db6930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:22.022262: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:24.595211: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:24.609033: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff1be38a9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:24.609048: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:27.173672: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:27.187021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5fbb66690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:27.187042: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:29.762019: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:29.775323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fefa97070e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:29.775339: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:32.407842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:32.421305: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8953deb6e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:32.421320: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:34.983963: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:34.997519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9674d3be00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:34.997534: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:37.529806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:37.542681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd81c72790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:37.542697: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:40.274905: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:40.287985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fed6e3f4ab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:40.288001: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:42.844218: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:42.857616: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f784a7940 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:42.857632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:45.454106: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:45.468146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf0c173230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:45.468161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:47.999965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:48.013127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe9598b58c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:48.013143: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:50.578197: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:50.591236: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8ca9d5ad70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:50.591252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:53.158839: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:53.173179: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa875590430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:53.173195: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:55.764896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:55.777913: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb245488c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:55.777929: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:11:58.375203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:11:58.389358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e0954e230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:11:58.389373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:00.968144: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:00.981837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcdc2b5e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:00.981852: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:03.554617: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:03.567838: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe29cc55970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:03.567859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:06.128746: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:06.141378: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2ad5395a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:06.141393: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:08.739395: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:08.753527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fabb64416a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:08.753542: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:11.306659: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:11.319712: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf4a4f96c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:11.319728: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:13.864018: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:13.877231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd14e1c320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:13.877246: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:16.444187: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:16.457607: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe255c74970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:16.457623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:19.042168: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:19.055333: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6a8e39270 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:19.055350: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:21.613610: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:21.627020: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7b0cc6290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:21.627035: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:24.179221: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:24.191918: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc7c9f40550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:24.191933: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:26.744717: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:26.757993: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff66baf1920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:26.758009: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 15:12:29.348595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 15:12:29.362646: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fae894b1740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 15:12:29.362662: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 26 -> 16\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v11.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
