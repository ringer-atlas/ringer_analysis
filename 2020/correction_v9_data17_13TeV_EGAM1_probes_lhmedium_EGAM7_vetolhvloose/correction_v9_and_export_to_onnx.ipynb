{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v9 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v9 r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 16:15:06,573 | Py.crossval_table                       INFO Reading file for v9 tag from /Volumes/castor/tuning_data/Zee/v9/*.v9_et*.r0/*/*.gz\n",
      "2020-12-27 16:15:06,573 | Py.crossval_table                       INFO There are 1250 files for this task...\n",
      "2020-12-27 16:15:06,574 | Py.crossval_table                       INFO Filling the table... \n",
      "2020-12-27 16:15:43,218 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v9/*.v9_et*.r0/*/*.gz', 'v9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_showers (InputLayer)      [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_rings_layer (Dense)       (None, 5)            505         Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_showers[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 10)           0           dense_rings_layer[0][0]          \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 5)            55          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            6           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings,data_shower], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1428.337246s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977510</td>\n",
       "      <td>3073</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>227593</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977553</td>\n",
       "      <td>3004</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978185</td>\n",
       "      <td>3138</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016724</td>\n",
       "      <td>227728</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978133</td>\n",
       "      <td>3044</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987806</td>\n",
       "      <td>4272</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>229975</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987785</td>\n",
       "      <td>4216</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.022469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988485</td>\n",
       "      <td>4420</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>230171</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988626</td>\n",
       "      <td>4383</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.023359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977567</td>\n",
       "      <td>3936</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>137832</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977532</td>\n",
       "      <td>3873</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.026960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227583  ...   \n",
       "1                      187639                  0.129701         227740  ...   \n",
       "2                      187639                  0.169837         229980  ...   \n",
       "3                      187639                  0.174527         230138  ...   \n",
       "4                      143657                  0.222321         137837  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977510               3073            187639        0.016377   \n",
       "1    0.978185               3138            187639        0.016724   \n",
       "2    0.987806               4272            187639        0.022767   \n",
       "3    0.988485               4420            187639        0.023556   \n",
       "4    0.977567               3936            143657        0.027399   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227593                  232819              0.977553   \n",
       "1                   227728                  232819              0.978133   \n",
       "2                   229975                  232819              0.987785   \n",
       "3                   230171                  232819              0.988626   \n",
       "4                   137832                  141000              0.977532   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         3004                      187639   \n",
       "1                         3044                      187639   \n",
       "2                         4216                      187639   \n",
       "3                         4383                      187639   \n",
       "4                         3873                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.016009  \n",
       "1                  0.016223  \n",
       "2                  0.022469  \n",
       "3                  0.023359  \n",
       "4                  0.026960  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 16:39:54,879 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v9 tuning', \n",
    "                                              'correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta4.onnx\n",
      "2020-12-27 16:41:08,087 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta4.onnx\n",
      "2020-12-27 16:42:04,250 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta4.onnx\n",
      "2020-12-27 16:43:00,187 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta4.onnx\n",
      "2020-12-27 16:43:56,030 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-27 16:40:13.277020: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:13.316029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b6d9f27d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:13.316045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:15.686559: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:15.699295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff356408360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:15.699310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:17.986804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:17.999597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8e894bcaa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:17.999612: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:20.263922: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:20.278095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9407027730 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:20.278118: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:22.541466: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:22.553715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd4d601acc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:22.553729: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:24.822914: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:24.838002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f832ad26790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:24.838019: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:27.097980: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:27.110804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc68dd01410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:27.110819: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:29.370687: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:29.384873: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff9fe4f0190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:29.384888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:31.639954: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:31.652280: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1af747320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:31.652300: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:33.912764: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:33.925925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff0c6d65ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:33.925941: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:36.174555: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:36.189045: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbbfbd57e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:36.189063: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:38.445117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:38.457870: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8ba7858b90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:38.457888: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:40.720304: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:40.735085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef35db6f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:40.735101: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:42.998846: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:43.011207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba6869dee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:43.011222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:45.261676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:45.273776: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c20ec0670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:45.273791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:47.493208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:47.505525: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8f0ce886d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:47.505539: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:49.729719: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:49.742891: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3597bd0e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:49.742905: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:51.957072: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:51.969762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc02bdbf850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:51.969777: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:54.191213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:54.203500: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa4a8ce6cb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:54.203514: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:56.438286: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:56.451030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb4fe5e72d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:56.451046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:40:58.704754: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:40:58.717357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f950dd999a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:40:58.717373: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:00.952427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:00.964705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6bd5aa6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:00.964721: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:03.220733: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:03.233589: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa860dad0e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:03.233604: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:05.474254: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:05.487159: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fddd1ddddf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:05.487174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:07.731942: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:07.744356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe8d7e028e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:07.744371: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:09.996040: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:10.008182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6e0dce4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:10.008199: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:12.250944: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:12.263684: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee457ab3f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:12.263700: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:14.516346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:14.528961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f87d7d9c3c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:14.528976: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:16.758959: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:16.771673: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a7ae98a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:16.771688: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:19.015508: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:19.027884: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f869e8be4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:19.027898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:21.250723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:21.263126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb84fc1590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:21.263142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:23.509266: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:23.522000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec71dc1a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:23.522017: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:25.726259: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:25.738635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0c5386990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:25.738650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:27.979763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:27.992414: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2f2401090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:27.992428: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:30.214002: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:30.226541: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4ece19e30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:30.226556: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:32.464653: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:32.477095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff307d4be80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:32.477110: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:34.733251: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:34.745686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82f1d34780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:34.745700: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:36.973490: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:36.985879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2a4e6bf20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:36.985894: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:39.206555: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:39.218911: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8fb807440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:39.218925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:41.442015: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:41.454437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5f264cd00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:41.454453: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:43.700022: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:43.712478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcbad705f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:43.712494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:45.926736: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:45.938792: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcdcdff5e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:45.938807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:48.195664: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:48.208617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95e9677eb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:48.208632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:50.452101: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:50.464416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa90fd91b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:50.464432: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:52.697945: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:52.710658: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff13c68d8c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:52.710673: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:54.935353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:54.947612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdc92672e30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:54.947627: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:57.190845: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:57.203425: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac635d3970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:57.203439: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:41:59.426355: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:41:59.438850: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd67160cac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:41:59.438869: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:01.671200: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:01.683724: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6f7e68e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:01.683739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:03.915035: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:03.927445: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feca8dad920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:03.927459: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:06.181850: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:06.194529: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1835d69a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:06.194547: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:08.397813: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:08.410182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc8cc6fa5e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:08.410196: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:10.607591: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:10.619976: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7f37c7bf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:10.619992: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:12.849239: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:12.861870: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9419e2cd60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:12.861894: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:15.076886: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:15.089350: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fafd95d3f30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:15.089365: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:17.309480: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:17.322085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff07db85970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:17.322112: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:19.533010: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:19.545292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe556e00ab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:19.545307: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:21.752775: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:21.765124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e824715b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:21.765139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:23.977998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:23.990324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe630659580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:23.990338: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:26.190426: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:26.202970: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa7fcc2dd00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:26.202984: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:28.426818: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:28.439328: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7d6d6b3a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:28.439343: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:30.654007: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:30.666086: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2665d0050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:30.666101: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:32.893328: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:32.905694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcb00986f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:32.905709: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:35.157885: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:35.170635: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec75575e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:35.170650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:37.395142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:37.408087: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc282e7d950 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:37.408102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:39.644195: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:39.656460: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe589e0a250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:39.656476: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:41.920924: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:41.933600: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe56855fab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:41.933615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:44.171916: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:44.184308: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa85045510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:44.184328: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:46.417357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:46.429739: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb28e6377b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:46.429753: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:48.649693: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:48.662000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9d15a1290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:48.662018: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:50.875831: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:50.888443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd8bef9200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:50.888458: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:53.139327: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:53.151524: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98f5ce66f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:53.151538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:55.369230: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:55.381872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fce51353a70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:55.381887: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:57.617949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:57.630290: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9af4cad8c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:57.630304: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:42:59.867469: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:42:59.879989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd923c14150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:42:59.880004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:02.105882: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:02.118179: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe5bdde76b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:02.118194: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:04.369926: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:04.382766: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb4a5649d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:04.382781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:06.621950: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:06.634131: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95167b6c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:06.634145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:08.864943: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:08.877771: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa22ed72e20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:08.877785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:11.084233: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:11.096846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff21d56f180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:11.096863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:13.313735: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:13.326397: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b3364e530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:13.326412: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:15.532619: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:15.545103: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe285c7280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:15.545120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:17.772264: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:17.784967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd34f18360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:17.784987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:19.978415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:19.991383: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf9645b7f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:19.991398: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:22.202381: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:22.214780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7185bc7c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:22.214794: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:24.431421: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:24.443932: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb4d16d1ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:24.443947: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:26.675166: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:26.687532: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd43f5aa820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:26.687547: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:28.907083: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:28.919559: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a6cc12130 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:28.919574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:31.150354: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:31.162841: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1a30a4410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:31.162856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:33.411026: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:33.423663: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9799eac1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:33.423677: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:35.617428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:35.629740: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2dd4003b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:35.629755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:37.854292: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:37.866672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9a4453720 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:37.866686: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:40.137673: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:40.150296: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf0db9d5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:40.150311: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:42.352054: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:42.364649: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feedde3b210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:42.364664: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:44.577259: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:44.589513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faf8f40f810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:44.589528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:46.811828: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:46.825061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffbe440a480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:46.825084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:49.023194: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:49.035664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8b2a4f5e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:49.035678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:51.244412: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:51.256608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff5c5f58160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:51.256622: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:53.482920: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:53.495601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fadaabe9640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:53.495628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-27 16:43:55.720324: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-27 16:43:55.732811: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9449eed150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-27 16:43:55.732826: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
