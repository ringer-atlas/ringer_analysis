{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v9 tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v9 r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.25/01\n",
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-29 18:56:42,187 | Py.crossval_table                       INFO Reading file for v9 tag from /Volumes/castor/tuning_data/Zee/v9/r1/*/*/*.gz\n",
      "2021-06-29 18:56:42,187 | Py.crossval_table                       INFO There are 2500 files for this task...\n",
      "2021-06-29 18:56:42,187 | Py.crossval_table                       INFO Filling the table... \n",
      "2021-06-29 18:57:55,763 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v9/r1/*/*/*.gz', 'v9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_showers (InputLayer)      [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_rings_layer (Dense)       (None, 5)            505         Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_showers[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 10)           0           dense_rings_layer[0][0]          \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 5)            55          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            6           dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 601\n",
      "Trainable params: 601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = cv.get_best_models(best_sorts, remove_last=False)[0][0]['model']\n",
    "tf.keras.utils.plot_model(model, to_file='model_v9_plot.pdf', \n",
    "                          show_shapes=True, \n",
    "                          show_layer_names=True,\n",
    "                          show_dtype=False,\n",
    "                          rankdir='TB',\n",
    "                          expand_nested=True,\n",
    "                          dpi=200)\n",
    "\n",
    "# v9 rg\n",
    "from saphyra import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "input  = layers.Input(shape=(100,), name = 'Input')\n",
    "dense  = layers.Dense(5, activation='relu', name='dense_layer')(input)\n",
    "dense  = layers.Dense(1,activation='linear', name='output_for_inference')(dense)\n",
    "output = layers.Activation('sigmoid', name='output_for_training')(dense)\n",
    "model = tf.keras.Model(input, output, name = \"model\")\n",
    "tf.keras.utils.plot_model(model, to_file='model_v9_rg_plot.pdf', \n",
    "                          show_shapes=True, \n",
    "                          show_layer_names=True,\n",
    "                          show_dtype=False,\n",
    "                          rankdir='TB',\n",
    "                          expand_nested=True,\n",
    "                          dpi=200)\n",
    "\n",
    "input  = layers.Input(shape=(6,), name = 'Input')\n",
    "dense  = layers.Dense(5, activation='relu', name='dense_layer')(input)\n",
    "dense  = layers.Dense(1,activation='linear', name='output_for_inference')(dense)\n",
    "output = layers.Activation('sigmoid', name='output_for_training')(dense)\n",
    "model = tf.keras.Model(input, output, name = \"model\")\n",
    "tf.keras.utils.plot_model(model, to_file='model_v9_ss_plot.pdf', \n",
    "                          show_shapes=True, \n",
    "                          show_layer_names=True,\n",
    "                          show_dtype=False,\n",
    "                          rankdir='TB',\n",
    "                          expand_nested=True,\n",
    "                          dpi=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    target = d['target']\n",
    "    avgmu = d['data'][:,0]\n",
    "    \n",
    "    return [data_rings,data_shower], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1772.676817s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227619</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>23318</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>227588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977532</td>\n",
       "      <td>3112</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>227602</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.977592</td>\n",
       "      <td>3057</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227780</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>24336</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>227742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978193</td>\n",
       "      <td>3144</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>227766</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.978296</td>\n",
       "      <td>3106</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.016553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229996</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>31867</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987780</td>\n",
       "      <td>4267</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>229977</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.987793</td>\n",
       "      <td>4190</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.022330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>230152</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>32748</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>230131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988455</td>\n",
       "      <td>4413</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>230141</td>\n",
       "      <td>232819</td>\n",
       "      <td>0.988498</td>\n",
       "      <td>4335</td>\n",
       "      <td>187639</td>\n",
       "      <td>0.023103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137861</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>31938</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977589</td>\n",
       "      <td>3965</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>137809</td>\n",
       "      <td>141000</td>\n",
       "      <td>0.977369</td>\n",
       "      <td>3880</td>\n",
       "      <td>143657</td>\n",
       "      <td>0.027009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   227619   \n",
       "1  medium_cutbased       0        0                   227780   \n",
       "2   loose_cutbased       0        0                   229996   \n",
       "3  vloose_cutbased       0        0                   230152   \n",
       "4   tight_cutbased       0        1                   137861   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232819              0.977666                        23318   \n",
       "1                  232819              0.978360                        24336   \n",
       "2                  232819              0.987876                        31867   \n",
       "3                  232819              0.988548                        32748   \n",
       "4                  141000              0.977742                        31938   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      187639                  0.124271         227588  ...   \n",
       "1                      187639                  0.129701         227742  ...   \n",
       "2                      187639                  0.169837         229974  ...   \n",
       "3                      187639                  0.174527         230131  ...   \n",
       "4                      143657                  0.222321         137840  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977532               3112            187639        0.016585   \n",
       "1    0.978193               3144            187639        0.016756   \n",
       "2    0.987780               4267            187639        0.022740   \n",
       "3    0.988455               4413            187639        0.023519   \n",
       "4    0.977589               3965            143657        0.027600   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   227602                  232819              0.977592   \n",
       "1                   227766                  232819              0.978296   \n",
       "2                   229977                  232819              0.987793   \n",
       "3                   230141                  232819              0.988498   \n",
       "4                   137809                  141000              0.977369   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                         3057                      187639   \n",
       "1                         3106                      187639   \n",
       "2                         4190                      187639   \n",
       "3                         4335                      187639   \n",
       "4                         3880                      143657   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.016292  \n",
       "1                  0.016553  \n",
       "2                  0.022330  \n",
       "3                  0.023103  \n",
       "4                  0.027009  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 13:07:27,291 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v9 tuning', \n",
    "                                              'correction_v9_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronTight.et4_eta4.onnx\n",
      "2021-03-06 13:09:21,246 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronMedium.et4_eta4.onnx\n",
      "2021-03-06 13:10:37,269 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronLoose.et4_eta4.onnx\n",
      "2021-03-06 13:11:47,311 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electronVeryLoose.et4_eta4.onnx\n",
      "2021-03-06 13:12:52,747 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 13:07:55.765780: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:07:55.796551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd8b0afd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:07:55.796617: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:00.076503: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:00.096908: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb659e0cc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:00.096925: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:03.443639: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:03.460246: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd8c8f7c20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:03.460263: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:06.219353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:06.235392: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea16dcb150 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:06.235462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:09.369059: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:09.382297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf6f9c71c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:09.382313: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:12.464944: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:12.487833: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9331569bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:12.487854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:17.197516: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:17.212518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faff55baf90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:17.212537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:20.541562: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:20.555662: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9c9f7bbe30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:20.555679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:24.569012: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:24.584030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffcd53cf740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:24.584045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:29.905891: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:29.921371: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f775a4d50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:29.921386: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:35.407735: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:35.425303: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9968dfad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:35.425321: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:38.857852: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:38.873777: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f94026f9b40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:38.873793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:42.271724: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:42.286196: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8040825ba0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:42.286220: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:45.311791: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:45.327086: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f97b5d729c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:45.327102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:49.402222: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:49.424762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc2bb52d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:49.424781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:52.903946: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:52.922776: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0c7ba8490 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:52.922791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:55.638203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:55.656825: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f94534b6b50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:55.656846: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:08:58.535269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:08:58.549638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9103b6c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:08:58.549652: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:01.569709: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:01.583017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff10f51fb40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:01.583033: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:04.612098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:04.625647: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d61e51d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:04.625661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:08.153023: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:08.166495: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2dcc2af00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:08.166511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:11.020353: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:11.033411: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb6a05903b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:11.033439: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:13.985583: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:14.006570: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e8ce314a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:14.006615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:17.052063: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:17.067262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd023ba8ab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:17.067279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:20.384061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:20.406436: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa5c9d5d1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:20.406453: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:23.888310: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:23.913161: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc2d8f7810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:23.913211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:26.945463: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:26.961780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6237e6700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:26.961795: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:29.827437: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:29.841180: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb12e2e33d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:29.841205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:32.440186: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:32.453435: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb11c6004a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:32.453451: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:35.063048: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:35.077148: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdd2ea99320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:35.077164: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:37.875942: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:37.890150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc084d351b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:37.890175: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:41.110683: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:41.124241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa328a36a30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:41.124256: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:45.318117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:45.340736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa185a7d8d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:45.340804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:48.521283: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:48.540341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd23b3bf800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:48.540358: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:51.594491: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:51.608900: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8813a4fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:51.608914: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:54.557359: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:54.572200: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f966a517060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:54.572219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:09:59.622563: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:09:59.641713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff6b82ee410 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:09:59.641736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:02.869746: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:02.883415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9198d655e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:02.883430: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:05.975371: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:05.994194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f817be48210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:05.994221: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:08.974415: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:08.988208: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a54c5b570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:08.988252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:11.865092: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:11.877920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80a33874b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:11.877936: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:14.663826: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:14.676720: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb3ee5c0eb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:14.676735: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:17.275743: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:17.289368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc365ad1ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:17.289388: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:20.014714: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:20.027595: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f978a9df3f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:20.027611: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:22.697006: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:22.711846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9adb4e3970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:22.711865: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:25.480826: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:25.495645: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd11932c360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:25.495665: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:28.150597: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:28.165343: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe881412de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:28.165360: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:30.781301: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:30.794974: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe909836ab0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:30.794995: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:33.337098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:33.350837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc966b891b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:33.350852: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:36.862439: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:36.878879: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc7998d7d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:36.878915: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:39.748696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:39.767467: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9888c7d710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:39.767488: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:42.822650: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:42.835797: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd5044e6450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:42.835814: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:45.557273: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:45.570076: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9390bc92d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:45.570091: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:48.160427: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:48.174443: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3838c7180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:48.174463: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:50.896710: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:50.910188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe228d9c310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:50.910210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:53.489627: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:53.502638: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fde0d0a3b80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:53.502653: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:56.059158: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:56.072371: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffe07d1f920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:56.072387: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:10:58.859603: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:10:58.875201: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd9f52b8f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:10:58.875217: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:01.859802: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:01.874122: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff50d355e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:01.874138: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:04.726931: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:04.743239: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb60cd4ff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:04.743294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:08.390733: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:08.410167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc0202e2360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:08.410182: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:11.123156: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:11.136237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdee3753c50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:11.136252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:13.685422: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:13.698619: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92413768a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:13.698634: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:16.452819: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:16.466048: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90ca35d900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:16.466064: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:19.476556: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:19.490388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd9ff948520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:19.490403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:22.299555: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:22.317809: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2b861ef40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:22.317841: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:25.008290: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:25.023212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faacc2cb8e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:25.023228: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:28.169417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:28.188583: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3df6f3d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:28.188602: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:31.233674: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:31.247009: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f813c6cf060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:31.247025: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:33.841057: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:33.855881: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faa9aeed3d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:33.855896: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:36.474577: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:36.487247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe498c22da0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:36.487262: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:39.055902: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:39.068630: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd1dc4b6700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:39.068646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:41.739367: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:41.752632: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd7f6d35e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:41.752647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:44.363744: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:44.377253: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8108566b00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:44.377268: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:46.924451: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:46.942318: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f82633520 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:46.942334: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:49.789314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:49.803058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe8904257e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:49.803074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:52.514778: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:52.527534: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83eb594280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:52.527550: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:55.068129: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:55.082514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f1dde5760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:55.082530: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:11:57.723328: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:11:57.736588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2ca1fa4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:11:57.736603: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:00.433204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:00.446772: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc1253d030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:00.446788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:02.978816: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:02.991921: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f99cbca2680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:02.991936: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:05.618971: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:05.632068: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fded6f48910 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:05.632082: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:08.197570: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:08.211508: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee88d6e7e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:08.211525: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:10.752488: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:10.765756: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc03450200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:10.765771: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:13.299243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:13.312494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a57e01af0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:13.312510: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:16.166494: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:16.179497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fac54ee2610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:16.179512: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:18.745295: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:18.758401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc1094eeeb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:18.758417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:21.282956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:21.296002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8cafcc3ba0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:21.296017: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:23.817563: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:23.830904: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9fbdd4d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:23.830919: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:26.375796: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:26.388802: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf25d9b590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:26.388818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:28.957464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:28.971159: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe7d2d84110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:28.971174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:31.571338: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:31.584855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb63d491a40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:31.584870: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:34.166793: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:34.180605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdde5be8980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:34.180621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:36.807417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:36.820691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc216569a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:36.820707: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:39.501262: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:39.514539: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffbe327f080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:39.514554: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:42.166837: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:42.180133: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa81ab52b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:42.180148: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:44.719513: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:44.733731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91a74ee9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:44.733747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:47.281626: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:47.294350: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff9857ce830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:47.294366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:49.860956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:49.874325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb2de49ea30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:49.874340: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 13:12:52.391472: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 13:12:52.405071: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa1fe4b16f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 13:12:52.405087: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v9.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
