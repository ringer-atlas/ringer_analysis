{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v2_el tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v2_el r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:24:57,318 | Py.crossval_table                       INFO Reading file for v2-el tag from /Volumes/castor/tuning_data/Zee_el/v2/r1/*/*/*.gz\n",
      "2021-03-06 17:24:57,319 | Py.crossval_table                       INFO There are 2500 files for this task...\n",
      "2021-03-06 17:24:57,319 | Py.crossval_table                       INFO Filling the table... \n",
      "2021-03-06 17:25:47,495 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee_el/v2/r1/*/*/*.gz', 'v2-el')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 1)       0           Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_1 (Conv1D)         (None, 99, 4)        12          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_2 (Conv1D)         (None, 98, 8)        72          conv1d_rings_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Input_shower_shapes (InputLayer [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_track_variables (InputLay [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           conv1d_rings_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_shower_shapes[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_track_variables_layer (De (None, 5)            20          Input_track_variables[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 794)          0           flatten[0][0]                    \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "                                                                 dense_track_variables_layer[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 16)           12720       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            17          dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,876\n",
      "Trainable params: 12,876\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "\n",
    "    has_track = d['data'][:,feature_names.index('L2Electron_hastrack')]\n",
    "    d['data'] = d['data'][has_track==True]\n",
    "    target = d['target'][has_track==True]\n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "    avgmu = d['data'][:,0]\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    data_etOverPt  = d['data'][:, feature_names.index('L2Electron_etOverPt')].reshape((n,1))\n",
    "    data_deta      = d['data'][:, feature_names.index('L2Electron_trkClusDeta')].reshape((n,1))\n",
    "    data_dphi      = d['data'][:, feature_names.index('L2Electron_trkClusDphi')].reshape((n,1))\n",
    "    data_track = np.concatenate( (data_etOverPt, data_deta, data_dphi), axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    return [data_rings,data_shower,data_track], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 1926.373708s.\n",
      "2021-03-06 17:57:46,914 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 17:57:50,141 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 17:57:53,240 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n",
      "2021-03-06 17:57:56,339 | Py.fit_table                         WARNING Retrieved positive angular factor of the linear correction, setting to 0!\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v2_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226834</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>13176</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>226810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977562</td>\n",
       "      <td>686</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>226802</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.977527</td>\n",
       "      <td>682</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.006432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226995</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>13752</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>226969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>711</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>226951</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.978170</td>\n",
       "      <td>699</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.006593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229203</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>18007</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987803</td>\n",
       "      <td>1054</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.009941</td>\n",
       "      <td>229199</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.987859</td>\n",
       "      <td>1034</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.009752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229358</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>18504</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>229340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988466</td>\n",
       "      <td>1095</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>229359</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>1077</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.010158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137521</td>\n",
       "      <td>140652</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>26154</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977640</td>\n",
       "      <td>1126</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>137469</td>\n",
       "      <td>140652</td>\n",
       "      <td>0.977370</td>\n",
       "      <td>1114</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.009469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   226834   \n",
       "1  medium_cutbased       0        0                   226995   \n",
       "2   loose_cutbased       0        0                   229203   \n",
       "3  vloose_cutbased       0        0                   229358   \n",
       "4   tight_cutbased       0        1                   137521   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232016              0.977666                        13176   \n",
       "1                  232016              0.978360                        13752   \n",
       "2                  232016              0.987876                        18007   \n",
       "3                  232016              0.988548                        18504   \n",
       "4                  140652              0.977742                        26154   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      106029                  0.124271         226810  ...   \n",
       "1                      106029                  0.129701         226969  ...   \n",
       "2                      106029                  0.169837         229186  ...   \n",
       "3                      106029                  0.174527         229340  ...   \n",
       "4                      117644                  0.222321         137507  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977562                686            106029        0.006470   \n",
       "1    0.978247                711            106029        0.006706   \n",
       "2    0.987803               1054            106029        0.009941   \n",
       "3    0.988466               1095            106029        0.010327   \n",
       "4    0.977640               1126            117644        0.009571   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   226802                  232016              0.977527   \n",
       "1                   226951                  232016              0.978170   \n",
       "2                   229199                  232016              0.987859   \n",
       "3                   229359                  232016              0.988548   \n",
       "4                   137469                  140652              0.977370   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                          682                      106029   \n",
       "1                          699                      106029   \n",
       "2                         1034                      106029   \n",
       "3                         1077                      106029   \n",
       "4                         1114                      117644   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.006432  \n",
       "1                  0.006593  \n",
       "2                  0.009752  \n",
       "3                  0.010158  \n",
       "4                  0.009469  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:57:58,543 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v2_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v2 el tuning', \n",
    "                                              'correction_v2_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta4.onnx\n",
      "2021-03-06 17:59:21,837 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta4.onnx\n",
      "2021-03-06 18:00:24,681 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta4.onnx\n",
      "2021-03-06 18:01:27,759 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as models/data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta4.onnx\n",
      "2021-03-06 18:02:30,660 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-06 17:58:20.096597: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:20.120705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcfd552e1e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:20.120727: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:22.697942: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:22.710904: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82d05bd0f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:22.710920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:25.213445: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:25.226713: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb26a530260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:25.226737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:27.750404: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:27.763136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fea0fd06570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:27.763151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:30.309016: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:30.321832: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4aa5d9a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:30.321848: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:32.843844: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:32.856645: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9fc9560ed0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:32.856661: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:35.372669: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:35.386676: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f855e5412c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:35.386700: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:37.879257: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:37.892552: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d00d18220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:37.892568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:40.417391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:40.430979: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa845c5ed00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:40.431009: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:42.960439: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:42.973149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9195d5e6b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:42.973177: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:45.469130: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:45.482874: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffab258c7d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:45.482889: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:47.962446: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:47.975766: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd42fcb3000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:47.975795: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:50.541459: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:50.554214: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fedc086fc20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:50.554229: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:53.077956: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:53.091585: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa448ded9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:53.091605: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:55.586276: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:55.598577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff3058c8de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:55.598594: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:58:58.105352: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:58:58.118323: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0489c7ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:58:58.118339: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:00.647929: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:00.660934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdff1c63090 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:00.660949: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:03.178229: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:03.192557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a4dd15f90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:03.192575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:05.730185: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:05.743262: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef3c861330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:05.743277: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:08.269971: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:08.283252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbf7942b870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:08.283266: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:10.777284: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:10.791887: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdc1dd0cf50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:10.791907: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:13.410507: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:13.424415: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2af542ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:13.424458: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:15.982922: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:15.995403: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8113c5c700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:15.995419: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:18.498367: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:18.511475: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda65e9e300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:18.511490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:21.031390: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:21.044671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcf24b2710 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:21.044691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:24.018386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:24.033113: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80f85d4690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:24.033136: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:26.540517: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:26.553469: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2feda7510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:26.553485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:29.196527: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:29.209604: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9d45985f50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:29.209618: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:31.722469: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:31.735074: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7ff7af7940 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:31.735089: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:34.251834: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:34.265152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd188f5a9d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:34.265168: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:36.862691: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:36.875615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc83beb36a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:36.875630: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:39.377578: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:39.390517: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb52bc5cc20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:39.390533: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:41.868710: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:41.882012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8281be8cc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:41.882027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:44.388548: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:44.401491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91a389b530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:44.401518: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:46.844805: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:46.857398: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa233c82ca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:46.857413: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:49.366373: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:49.379325: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd029dafe30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:49.379339: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:51.874040: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:51.887171: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f875ae9bf70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:51.887186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:54.372831: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:54.385608: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a17501820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:54.385629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:56.855696: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:56.868169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffdf1be24f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:56.868184: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 17:59:59.343756: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 17:59:59.356172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f94940a1650 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 17:59:59.356189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:01.841399: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:01.853783: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffd86d49610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:01.853799: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:04.348208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:04.361469: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fad2e65c4d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:04.361484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:06.847910: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:06.862136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe45246b2a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:06.862151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:09.371081: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:09.384097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f870c3d6770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:09.384112: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:11.857660: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:11.870391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9e42d89690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:11.870405: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:14.357468: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:14.370434: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90744571a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:14.370448: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:16.847647: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:16.860273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f97227aa590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:16.860288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:19.350464: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:19.363618: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc60236a660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:19.363632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:21.814947: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:21.827577: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a1ac39f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:21.827593: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:24.309534: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:24.322776: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe97e452fa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:24.322791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:26.933307: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:26.949839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc45fd6b920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:26.949856: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:29.533609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:29.546169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff9e44e4b00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:29.546184: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:31.999268: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:32.011834: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff89c5a00b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:32.011850: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:34.493572: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:34.506656: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff8b465f1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:34.506671: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:36.997232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:37.010143: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8b750dc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:37.010157: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:39.493499: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:39.506925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f857fd6f1d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:39.506941: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:41.996369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:42.009518: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc85be03220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:42.009533: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:44.518341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:44.531242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2ff549d50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:44.531258: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:46.992626: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:47.005390: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd876e51fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:47.005404: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:49.531930: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:49.544275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faf8ad86bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:49.544291: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:52.070167: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:52.083226: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc461ca15a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:52.083241: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:54.593926: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:54.606996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92a4ba83c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:54.607011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:57.113676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:57.126322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe8bee7ad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:57.126337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:00:59.629622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:00:59.642282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff548474cd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:00:59.642297: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:02.137137: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:02.149985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd6925b04e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:02.150000: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:04.642818: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:04.655631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe04a7973c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:04.655646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:07.114981: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:07.128423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8604bdee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:07.128438: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:09.649565: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:09.663474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7f647dffd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:09.663490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:12.204585: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:12.223787: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd818d92db0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:12.223805: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:14.728792: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:14.741489: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe0b5e69140 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:14.741506: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:17.241523: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:17.254380: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faee95e1fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:17.254395: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:19.798635: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:19.811599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2295137f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:19.811614: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:22.360039: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:22.373320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd078388c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:22.373337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:24.855836: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:24.868826: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82e5d630a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:24.868841: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:27.376699: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:27.389898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff908c7b580 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:27.389918: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:29.919128: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:29.932581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8601958a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:29.932600: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:32.444122: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:32.457637: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9f2d68300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:32.457663: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:34.946550: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:34.959588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff79e6b5440 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:34.959604: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:37.419807: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:37.432924: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa952540120 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:37.432939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:39.942817: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:39.955533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa44ce02320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:39.955548: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:42.450249: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:42.463333: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd8ba4b66b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:42.463349: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:44.953771: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:44.966285: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9ee5cfb250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:44.966301: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:47.429648: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:47.442194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb326aeba10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:47.442210: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:49.936945: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:49.949789: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe1eedc26b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:49.949806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:52.425751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:52.438176: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb07883060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:52.438191: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:54.908949: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:54.921741: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f98175f4790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:54.921756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:57.415525: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:57.428212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6fdd65db0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:57.428228: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:01:59.950713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:01:59.963947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb625c2c90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:01:59.963962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:02.472783: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:02.485528: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a8257dfa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:02.485543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:04.988988: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:05.001682: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f80875165a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:05.001696: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:07.502882: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:07.516199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fde9d503fc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:07.516214: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:10.055269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:10.068156: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6a8d16430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:10.068171: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:12.567162: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:12.579438: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb9eedf77c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:12.579453: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:15.124967: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:15.137934: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf7ccc5e50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:15.137955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:17.623984: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:17.636986: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb23b1008c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:17.637003: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:20.098364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:20.111160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f850239c600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:20.111179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:22.648349: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:22.662574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9b82ba7ac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:22.662596: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:25.135273: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:25.147989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa9ae5e9750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:25.148004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:27.691005: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:27.704336: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbdfa3e61a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:27.704353: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2021-03-06 18:02:30.280100: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-03-06 18:02:30.293513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9bcaf373a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-03-06 18:02:30.293528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
