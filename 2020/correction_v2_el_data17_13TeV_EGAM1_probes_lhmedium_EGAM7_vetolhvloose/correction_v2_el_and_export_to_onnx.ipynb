{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set references for v2_el tuning and export to ONNX\n",
    "\n",
    "This notebook is dedicated to apply the linear correction in the neural network output w.r.t the avgmu and export the v9 best models to ONNX/keras format. Usually, keras versions is used into the prometheus framework. The ONNX version will be used into the athena framework.\n",
    "\n",
    "**NOTE**: ONNX is a Microsoft API for inference.\n",
    "\n",
    "**NOTE**: We will export all tunings from v2_el r0 derivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.23/01\n",
      "Using all sub packages with ROOT dependence\n"
     ]
    }
   ],
   "source": [
    "from kolmov import crossval_table, get_color_fader, fit_table\n",
    "import saphyra\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_op_dict(op):\n",
    "    d = {\n",
    "              op+'_pd_ref'    : \"reference/\"+op+\"_cutbased/pd_ref#0\",\n",
    "              op+'_fa_ref'    : \"reference/\"+op+\"_cutbased/fa_ref#0\",\n",
    "              op+'_sp_ref'    : \"reference/\"+op+\"_cutbased/sp_ref\",\n",
    "              op+'_pd_val'    : \"reference/\"+op+\"_cutbased/pd_val#0\",\n",
    "              op+'_fa_val'    : \"reference/\"+op+\"_cutbased/fa_val#0\",\n",
    "              op+'_sp_val'    : \"reference/\"+op+\"_cutbased/sp_val\",\n",
    "              op+'_pd_op'     : \"reference/\"+op+\"_cutbased/pd_op#0\",\n",
    "              op+'_fa_op'     : \"reference/\"+op+\"_cutbased/fa_op#0\",\n",
    "              op+'_sp_op'     : \"reference/\"+op+\"_cutbased/sp_op\",\n",
    "\n",
    "              # Counts\n",
    "              op+'_pd_ref_passed'    : \"reference/\"+op+\"_cutbased/pd_ref#1\",\n",
    "              op+'_fa_ref_passed'    : \"reference/\"+op+\"_cutbased/fa_ref#1\",\n",
    "              op+'_pd_ref_total'     : \"reference/\"+op+\"_cutbased/pd_ref#2\",\n",
    "              op+'_fa_ref_total'     : \"reference/\"+op+\"_cutbased/fa_ref#2\",\n",
    "              op+'_pd_val_passed'    : \"reference/\"+op+\"_cutbased/pd_val#1\",\n",
    "              op+'_fa_val_passed'    : \"reference/\"+op+\"_cutbased/fa_val#1\",\n",
    "              op+'_pd_val_total'     : \"reference/\"+op+\"_cutbased/pd_val#2\",\n",
    "              op+'_fa_val_total'     : \"reference/\"+op+\"_cutbased/fa_val#2\",\n",
    "              op+'_pd_op_passed'     : \"reference/\"+op+\"_cutbased/pd_op#1\",\n",
    "              op+'_fa_op_passed'     : \"reference/\"+op+\"_cutbased/fa_op#1\",\n",
    "              op+'_pd_op_total'      : \"reference/\"+op+\"_cutbased/pd_op#2\",\n",
    "              op+'_fa_op_total'      : \"reference/\"+op+\"_cutbased/fa_op#2\",\n",
    "    }\n",
    "    return d\n",
    "\n",
    "tuned_info = collections.OrderedDict( {\n",
    "              # validation\n",
    "              \"max_sp_val\"      : 'summary/max_sp_val',\n",
    "              \"max_sp_pd_val\"   : 'summary/max_sp_pd_val#0',\n",
    "              \"max_sp_fa_val\"   : 'summary/max_sp_fa_val#0',\n",
    "              # Operation\n",
    "              \"max_sp_op\"       : 'summary/max_sp_op',\n",
    "              \"max_sp_pd_op\"    : 'summary/max_sp_pd_op#0',\n",
    "              \"max_sp_fa_op\"    : 'summary/max_sp_fa_op#0',\n",
    "              } )\n",
    "\n",
    "tuned_info.update(create_op_dict('tight'))\n",
    "tuned_info.update(create_op_dict('medium'))\n",
    "tuned_info.update(create_op_dict('loose'))\n",
    "tuned_info.update(create_op_dict('vloose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "etbins = [15, 20, 30, 40, 50, 1000000]\n",
    "etabins = [0.0, 0.8, 1.37, 1.54, 2.37, 2.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Reading all tunings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv  = crossval_table( tuned_info, etbins = etbins , etabins = etabins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 22:30:09,564 | Py.crossval_table                       INFO Reading file for v2-el tag from /Volumes/castor/tuning_data/Zee/v2_el/*.r0/*/*.gz\n",
      "2020-12-27 22:30:09,564 | Py.crossval_table                       INFO There are 500 files for this task...\n",
      "2020-12-27 22:30:09,564 | Py.crossval_table                       INFO Filling the table... \n",
      "2020-12-27 22:30:22,867 | Py.crossval_table                       INFO End of fill step, a pandas DataFrame was created...\n"
     ]
    }
   ],
   "source": [
    "cv.fill(  '/Volumes/castor/tuning_data/Zee/v2_el/*.r0/*/*.gz', 'v2-el')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Get best inits and sorts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_inits = cv.filter_inits(\"max_sp_val\")\n",
    "best_sorts = cv.filter_sorts( best_inits , 'max_sp_op')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Get best models:\n",
    "\n",
    "Get all best models for each bin. Expected to be 25 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = cv.get_best_models(best_sorts, remove_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_rings (InputLayer)        [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 1)       0           Input_rings[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_1 (Conv1D)         (None, 98, 4)        16          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_rings_2 (Conv1D)         (None, 96, 8)        104         conv1d_rings_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Input_shower_shapes (InputLayer [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_track_variables (InputLay [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 768)          0           conv1d_rings_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_shower_layer (Dense)      (None, 5)            35          Input_shower_shapes[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_track_variables_layer (De (None, 5)            20          Input_track_variables[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 778)          0           flatten[0][0]                    \n",
      "                                                                 dense_shower_layer[0][0]         \n",
      "                                                                 dense_track_variables_layer[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, 16)           12464       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output_for_inference (Dense)    (None, 1)            17          dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 12,656\n",
      "Trainable params: 12,656\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0]['model'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Linear correction:\n",
    "\n",
    "Here we will set all thresholds to operate as the same pd reference from cut-based using the pileup linear correction strategy. As the classifier efficiency has some \"dependence\" w.r.t the pileup we adopt the linear adjustment to \"fix\" the trigger efficiency. Here we will \"fix\" the neural network threshold w.r.t the pileup. \n",
    "\n",
    "### 2.1) Get all PD/Fas values:\n",
    "\n",
    "Read all reference values from the storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all pd/fa from reference file\n",
    "ref_path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/references/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.ref.pic.gz'\n",
    "ref_paths = [[ ref_path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]\n",
    "ref_matrix = [[ {} for eta in range(5)] for et in range(5)]\n",
    "references = ['tight_cutbased', 'medium_cutbased' , 'loose_cutbased', 'vloose_cutbased']\n",
    "from saphyra.core import ReferenceReader\n",
    "for et_bin in range(5):\n",
    "    for eta_bin in range(5):\n",
    "        for name in references:\n",
    "            refObj = ReferenceReader().load(ref_paths[et_bin][eta_bin])\n",
    "            pd = refObj.getSgnPassed(name)/refObj.getSgnTotal(name)\n",
    "            fa = refObj.getBkgPassed(name)/refObj.getBkgTotal(name)\n",
    "            ref_matrix[et_bin][eta_bin][name] = {'pd':pd, 'fa':fa}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Create data generator:\n",
    "\n",
    "Since each tuning models is fed by a different data organization, we need to create a generator to open the data file, prepare the matrix and apply some pre-processing (if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator( path ):\n",
    "    def norm1( data ):\n",
    "        norms = np.abs( data.sum(axis=1) )\n",
    "        norms[norms==0] = 1\n",
    "        return data/norms[:,None]\n",
    "    from Gaugi import load\n",
    "    d = load(path)\n",
    "    feature_names = d['features'].tolist()\n",
    "\n",
    "\n",
    "    has_track = d['data'][:,feature_names.index('L2Electron_hastrack')]\n",
    "    d['data'] = d['data'][has_track==True]\n",
    "    target = d['target'][has_track==True]\n",
    "    # extract rings\n",
    "    data_rings = norm1(d['data'][:,1:101])\n",
    "    avgmu = d['data'][:,0]\n",
    "    # How many events?\n",
    "    n = d['data'].shape[0]\n",
    "    \n",
    "\n",
    "    # extract all shower shapes\n",
    "    data_reta   = d['data'][:, feature_names.index('L2Calo_reta')].reshape((n,1)) / 1.0\n",
    "    data_eratio = d['data'][:, feature_names.index('L2Calo_eratio')].reshape((n,1)) / 1.0\n",
    "    data_f1     = d['data'][:, feature_names.index('L2Calo_f1')].reshape((n,1)) / 0.6\n",
    "    data_f3     = d['data'][:, feature_names.index('L2Calo_f3')].reshape((n,1)) / 0.04\n",
    "    data_weta2  = d['data'][:, feature_names.index('L2Calo_weta2')].reshape((n,1)) / 0.02\n",
    "    data_wstot  = d['data'][:, feature_names.index('L2Calo_wstot')].reshape((n,1)) / 1.0\n",
    "    # Fix all shower shapes variables\n",
    "    data_eratio[data_eratio>10.0]=0\n",
    "    data_eratio[data_eratio>1.]=1.0\n",
    "    data_wstot[data_wstot<-99]=0\n",
    "    data_shower = np.concatenate( (data_reta,data_eratio,data_f1,data_f3,data_weta2, data_wstot), axis=1)\n",
    "    \n",
    "    data_etOverPt  = d['data'][:, feature_names.index('L2Electron_etOverPt')].reshape((n,1))\n",
    "    data_deta      = d['data'][:, feature_names.index('L2Electron_trkClusDeta')].reshape((n,1))\n",
    "    data_dphi      = d['data'][:, feature_names.index('L2Electron_trkClusDphi')].reshape((n,1))\n",
    "    data_track = np.concatenate( (data_etOverPt, data_deta, data_dphi), axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    return [data_rings,data_shower,data_track], target, avgmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Volumes/castor/cern_data/files/Zee/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97/data17_13TeV.AllPeriods.sgn.probes_lhmedium_EGAM1.bkg.VProbes_EGAM7.GRL_v97_et{ET}_eta{ETA}.npz'\n",
    "paths = [[ path.format(ET=et,ETA=eta) for eta in range(5)] for et in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table class\n",
    "ct  = fit_table( generator, etbins , etabins, 0.02, 0.5, 16, 60, xmin_percentage=0.05, xmax_percentage=99.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Apply linear correction:\n",
    "\n",
    "**NOTE**: Take about 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying ATLAS style settings...\n",
      "Fitting... |############################################################| 25/25\n",
      "Fitting... ... finished task in 2175.451528s.\n"
     ]
    }
   ],
   "source": [
    "# Fill it\n",
    "ct.fill(paths, best_models, ref_matrix,'correction_v2_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "      <th>reference_signal_passed</th>\n",
       "      <th>reference_signal_total</th>\n",
       "      <th>reference_signal_eff</th>\n",
       "      <th>reference_background_passed</th>\n",
       "      <th>reference_background_total</th>\n",
       "      <th>reference_background_eff</th>\n",
       "      <th>signal_passed</th>\n",
       "      <th>...</th>\n",
       "      <th>signal_eff</th>\n",
       "      <th>background_passed</th>\n",
       "      <th>background_total</th>\n",
       "      <th>background_eff</th>\n",
       "      <th>signal_corrected_passed</th>\n",
       "      <th>signal_corrected_total</th>\n",
       "      <th>signal_corrected_eff</th>\n",
       "      <th>background_corrected_passed</th>\n",
       "      <th>background_corrected_total</th>\n",
       "      <th>background_corrected_eff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226834</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.977666</td>\n",
       "      <td>13176</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.124271</td>\n",
       "      <td>226802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977527</td>\n",
       "      <td>752</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>226797</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.977506</td>\n",
       "      <td>727</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.006857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medium_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226995</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.978360</td>\n",
       "      <td>13752</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.129701</td>\n",
       "      <td>226972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978260</td>\n",
       "      <td>770</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>226980</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.978295</td>\n",
       "      <td>747</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.007045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229203</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.987876</td>\n",
       "      <td>18007</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.169837</td>\n",
       "      <td>229182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987785</td>\n",
       "      <td>1094</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>229163</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.987703</td>\n",
       "      <td>1080</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.010186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vloose_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>229358</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.988548</td>\n",
       "      <td>18504</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.174527</td>\n",
       "      <td>229339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>1134</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>229323</td>\n",
       "      <td>232016</td>\n",
       "      <td>0.988393</td>\n",
       "      <td>1113</td>\n",
       "      <td>106029</td>\n",
       "      <td>0.010497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tight_cutbased</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>137521</td>\n",
       "      <td>140652</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>26154</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.222321</td>\n",
       "      <td>137501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977597</td>\n",
       "      <td>1279</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.010872</td>\n",
       "      <td>137519</td>\n",
       "      <td>140652</td>\n",
       "      <td>0.977725</td>\n",
       "      <td>1244</td>\n",
       "      <td>117644</td>\n",
       "      <td>0.010574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  et_bin  eta_bin  reference_signal_passed  \\\n",
       "0   tight_cutbased       0        0                   226834   \n",
       "1  medium_cutbased       0        0                   226995   \n",
       "2   loose_cutbased       0        0                   229203   \n",
       "3  vloose_cutbased       0        0                   229358   \n",
       "4   tight_cutbased       0        1                   137521   \n",
       "\n",
       "   reference_signal_total  reference_signal_eff  reference_background_passed  \\\n",
       "0                  232016              0.977666                        13176   \n",
       "1                  232016              0.978360                        13752   \n",
       "2                  232016              0.987876                        18007   \n",
       "3                  232016              0.988548                        18504   \n",
       "4                  140652              0.977742                        26154   \n",
       "\n",
       "   reference_background_total  reference_background_eff  signal_passed  ...  \\\n",
       "0                      106029                  0.124271         226802  ...   \n",
       "1                      106029                  0.129701         226972  ...   \n",
       "2                      106029                  0.169837         229182  ...   \n",
       "3                      106029                  0.174527         229339  ...   \n",
       "4                      117644                  0.222321         137501  ...   \n",
       "\n",
       "   signal_eff  background_passed  background_total  background_eff  \\\n",
       "0    0.977527                752            106029        0.007092   \n",
       "1    0.978260                770            106029        0.007262   \n",
       "2    0.987785               1094            106029        0.010318   \n",
       "3    0.988462               1134            106029        0.010695   \n",
       "4    0.977597               1279            117644        0.010872   \n",
       "\n",
       "   signal_corrected_passed  signal_corrected_total  signal_corrected_eff  \\\n",
       "0                   226797                  232016              0.977506   \n",
       "1                   226980                  232016              0.978295   \n",
       "2                   229163                  232016              0.987703   \n",
       "3                   229323                  232016              0.988393   \n",
       "4                   137519                  140652              0.977725   \n",
       "\n",
       "   background_corrected_passed  background_corrected_total  \\\n",
       "0                          727                      106029   \n",
       "1                          747                      106029   \n",
       "2                         1080                      106029   \n",
       "3                         1113                      106029   \n",
       "4                         1244                      117644   \n",
       "\n",
       "   background_corrected_eff  \n",
       "0                  0.006857  \n",
       "1                  0.007045  \n",
       "2                  0.010186  \n",
       "3                  0.010497  \n",
       "4                  0.010574  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.table().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Create beamer report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-28 00:05:06,525 | Py.BeamerTexReportTemplate1             INFO Started creating beamer file correction_v2_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf latex code...\n"
     ]
    }
   ],
   "source": [
    "ct.dump_beamer_table(ct.table(), best_models, 'data17_13TeV v2 el tuning', \n",
    "                                              'correction_v2_el_data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Export all tunings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronTight.et4_eta4.onnx\n",
      "2020-12-28 00:07:06,024 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerTightTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronMedium.et4_eta4.onnx\n",
      "2020-12-28 00:08:11,994 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerMediumTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronLoose.et4_eta4.onnx\n",
      "2020-12-28 00:09:11,078 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerLooseTriggerConfig.conf.\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et0_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et1_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et2_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et3_eta4.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta0.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta1.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta2.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta3.onnx\n",
      "Saving ONNX file as data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electronVeryLoose.et4_eta4.onnx\n",
      "2020-12-28 00:10:15,562 | Py.fit_table                            INFO Export all tuning configuration to ElectronRingerVeryLooseTriggerConfig.conf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-28 00:05:28.517228: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:28.538939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c58451780 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:28.538960: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:30.941526: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:30.953553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f891dd1fac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:30.953568: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:33.684834: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:33.700930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffaee4d3750 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:33.700946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:37.074753: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:37.087521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe4c4de2cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:37.087535: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:40.760781: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:40.777572: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd47e69d640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:40.777595: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:44.059223: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:44.077039: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7faa98bbc850 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:44.077054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:46.653748: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:46.666917: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f862c427330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:46.666931: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:49.135676: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:49.149046: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd2a7c3a220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:49.149070: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:51.818623: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:51.832709: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f913953bc20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:51.832724: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:54.539931: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:54.554182: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82764c4860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:54.554202: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:05:57.503944: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:05:57.527542: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcc78bd1a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:05:57.527564: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:02.039050: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:02.059169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa8ceae4e30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:02.059190: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:07.203406: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:07.228830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7feb9dc2d540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:07.228852: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:12.103576: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:12.130846: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe815e65230 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:12.130869: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:16.754917: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:16.781427: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe80641dd10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:16.781450: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:21.856363: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:21.885779: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f95a0d38d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:21.885803: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:26.978275: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:27.003692: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbe9d450370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:27.003716: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:31.751226: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:31.785766: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9959da6d10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:31.785792: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:36.794569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:36.821229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91ed36e240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:36.821254: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:41.624162: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:41.653824: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb21b4143e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:41.653849: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:46.374390: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:46.404555: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff39006bbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:46.404578: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:51.256723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:51.286321: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa8c83d79a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:51.286348: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:06:56.371731: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:06:56.399271: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd1de9f42d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:06:56.399302: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:01.311797: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:01.336439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f981cfafbb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:01.336462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:05.451560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:05.474468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96f446cc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:05.474490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:09.428965: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:09.451026: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa56b8acbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:09.451049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:13.341539: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:13.363876: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd723a4700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:13.363898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:17.277025: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:17.296996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc49ebbc5f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:17.297018: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:21.203648: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:21.220652: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb99b5d52c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:21.220672: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:23.940916: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:23.954034: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2aaad3f60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:23.954049: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:26.313055: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:26.326220: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd50a565260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:26.326238: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:28.729447: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:28.741987: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc75fe62f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:28.742002: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:31.142490: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:31.155614: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda65323df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:31.155629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:33.558132: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:33.571048: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8a0260a430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:33.571063: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:35.981736: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:35.994400: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe1ff7d4700 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:35.994416: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:38.398806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:38.411627: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f96b75f2020 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:38.411642: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:40.763722: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:40.776621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3f35a2320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:40.776636: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:43.159560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:43.172499: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdea9448240 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:43.172514: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:45.532252: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:45.547313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffddebb0080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:45.547328: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:47.956027: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:47.968959: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff16dcca510 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:47.968974: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:50.326359: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:50.341191: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9dfe79a320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:50.341207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:52.675997: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:52.688479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb704ef62e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:52.688494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:55.063941: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:55.077807: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd12051d790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:55.077830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:57.404123: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:57.417275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91748e1170 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:57.417293: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:07:59.751881: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:07:59.765216: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9687e42e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:07:59.765232: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:02.122035: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:02.135013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbc4bf78740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:02.135028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:04.466804: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:04.480413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8fced1f4a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:04.480428: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:06.855715: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:06.868586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe13e5b1630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:06.868601: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:09.229863: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:09.242442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4071e6e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:09.242456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:11.589752: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:11.601719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f90a3ef80e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:11.601734: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:13.950055: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:13.963038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8479cf6e10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:13.963053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:16.292429: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:16.305166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0cedbf190 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:16.305181: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:18.720001: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:18.732735: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbd92720a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:18.732759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:21.076124: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:21.088764: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdec25caec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:21.088779: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:23.421815: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:23.436308: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa6a7d750a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:23.436324: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:25.761994: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:25.774673: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7face3daf200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:25.774689: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:28.155204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:28.168160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f81904d90e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:28.168176: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:30.554689: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:30.567413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fecbfc2dc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:30.567428: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:32.940842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:32.953837: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92dcd6e210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:32.953854: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:35.285935: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:35.298939: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f93667344b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:35.298954: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:37.669937: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:37.682861: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe85ed5c730 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:37.682879: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:40.015613: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:40.028847: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc59e389980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:40.028861: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:42.386475: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:42.399324: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f861356a630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:42.399342: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:44.736623: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:44.749456: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdcecd711e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:44.749471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:47.091721: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:47.104181: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4a86803e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:47.104196: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:49.456732: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:49.469125: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffafb509c50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:49.469140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:51.790842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:51.803302: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8663d82de0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:51.803325: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:54.165564: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:54.178428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9aded41f70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:54.178443: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:56.517242: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:56.530248: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcb0f5c2620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:56.530262: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:08:58.901749: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:08:58.914355: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc28f50fd90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:08:58.914369: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:01.253792: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:01.266479: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda85c91b30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:01.266494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:03.609689: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:03.622058: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc93b008b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:03.622073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:05.963339: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:05.975997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f84cf3478f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:05.976012: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:08.338184: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:08.350748: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fec14051610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:08.350762: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:10.669336: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:10.683938: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc71a63d4e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:10.683954: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:13.034609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:13.047484: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa27581a50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:13.047500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:15.400142: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:15.412613: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7facde499a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:15.412628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:17.733505: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:17.746019: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f93f2f4c5e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:17.746034: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:20.086559: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:20.099478: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9f633c2e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:20.099493: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:22.416312: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:22.429639: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcf8f18e530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:22.429655: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:24.775958: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:24.788543: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffa05d6cbe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:24.788560: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:27.126830: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:27.139292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb7f8877af0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:27.139307: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:29.491524: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:29.504416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f92128dc7c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:29.504431: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:31.809109: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:31.821681: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc4cd1ed60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:31.821696: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:34.152891: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:34.165468: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd40f54bde0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:34.165483: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:36.522084: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:36.534525: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb0eaf86d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:36.534543: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:38.895957: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:38.908773: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f980b356010 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:38.908791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:41.229670: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:41.241985: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ffc3bdc3a10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:41.242002: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:45.222443: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:45.250878: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdf5633eb70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:45.250898: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:48.417567: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:48.436800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbad638c530 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:48.436816: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:51.457565: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:51.470611: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9c4d5580f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:51.470625: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:54.424280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:54.441098: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff4f62df380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:54.441123: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:57.208925: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:57.221896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9225506800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:57.221911: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:09:59.887017: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:09:59.904194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa83ad3f860 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:09:59.904216: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:10:03.107842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:10:03.123388: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fda60bc1ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:10:03.123403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:10:05.633442: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:10:05.646238: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8301bf6fb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:10:05.646253: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:10:08.010228: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:10:08.023612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef4d406ee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:10:08.023627: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:10:10.389253: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:10:10.401952: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2f6deb920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:10:10.401970: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:10:12.762328: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:10:12.775093: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f927745ca80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:10:12.775108: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n",
      "2020-12-28 00:10:15.160302: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-12-28 00:10:15.173179: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3013f8610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-28 00:10:15.173193: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 31 -> 19\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "model_name_format = 'data17_13TeV_EGAM1_probes_lhmedium_EGAM7_vetolhvloose.model_v2_el.electron{op}.et%d_eta%d'\n",
    "config_name_format = 'ElectronRinger{op}TriggerConfig.conf'\n",
    "for idx, op in enumerate(['Tight','Medium','Loose','VeryLoose']):\n",
    "    ct.export(best_models, \n",
    "              model_name_format.format(op=op), \n",
    "              config_name_format.format(op=op), \n",
    "              references[idx], \n",
    "              to_onnx=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
